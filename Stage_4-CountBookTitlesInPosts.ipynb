{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Book Titles from The Posts\n",
    "\n",
    "For every post id: get the actual version of the post, normalize it and search for book titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import re\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "from Functions import normalize_text, get_occurrences_for_post\n",
    "\n",
    "NON_ALPHANUMERIC = re.compile(r'[\\W_]+')\n",
    "SUBREDDIT_NAME = 'books'\n",
    "EXTRACTED_BOOKS_PATH = './data/books.csv'\n",
    "IDS_PATH = './data/post_ids.csv'\n",
    "STORED_POSTS_PATH = './data/stored_posts.csv'\n",
    "FAUX_TITLES_PATH = Path('./data/faux_book_titles')\n",
    "BOOK_COUNT_DF = './data/book_counts_raw.csv'\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Book Titles\n",
    "\n",
    "And compile them into a regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    Title  \\\n0                                          006 and a Half   \n1                                                01-01-00   \n2                                                   05:58   \n3       08 the Planet of the Tortoise Driver Little Pr...   \n4                           10,000 ways to say I love you   \n...                                                   ...   \n110477                         Zvezdy--kholodnye igrushki   \n110478                                           Zvirahwe   \n110479                                   The Z Was Zapped   \n110480  Zweite Auflage im Altertum; kulturgeschichtlic...   \n110481                           Zyj wystarczajaco dobrze   \n\n                                               Normalized  \n0                                             006andahalf  \n1                                                  010100  \n2                                                    0558  \n3              08theplanetofthetortoisedriverlittleprince  \n4                                  10000waystosayiloveyou  \n...                                                   ...  \n110477                            zvezdykholodnyeigrushki  \n110478                                           zvirahwe  \n110479                                         zwaszapped  \n110480  zweiteauflageimaltertumkulturgeschichtlichestu...  \n110481                             zyjwystarczajacodobrze  \n\n[110482 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Title</th>\n      <th>Normalized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>006 and a Half</td>\n      <td>006andahalf</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01-01-00</td>\n      <td>010100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>05:58</td>\n      <td>0558</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>08 the Planet of the Tortoise Driver Little Pr...</td>\n      <td>08theplanetofthetortoisedriverlittleprince</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10,000 ways to say I love you</td>\n      <td>10000waystosayiloveyou</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>110477</th>\n      <td>Zvezdy--kholodnye igrushki</td>\n      <td>zvezdykholodnyeigrushki</td>\n    </tr>\n    <tr>\n      <th>110478</th>\n      <td>Zvirahwe</td>\n      <td>zvirahwe</td>\n    </tr>\n    <tr>\n      <th>110479</th>\n      <td>The Z Was Zapped</td>\n      <td>zwaszapped</td>\n    </tr>\n    <tr>\n      <th>110480</th>\n      <td>Zweite Auflage im Altertum; kulturgeschichtlic...</td>\n      <td>zweiteauflageimaltertumkulturgeschichtlichestu...</td>\n    </tr>\n    <tr>\n      <th>110481</th>\n      <td>Zyj wystarczajaco dobrze</td>\n      <td>zyjwystarczajacodobrze</td>\n    </tr>\n  </tbody>\n</table>\n<p>110482 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 779 ms (started: 2022-10-26 18:36:34 +02:00)\n"
     ]
    }
   ],
   "source": [
    "book_titles_df = pd.read_csv(EXTRACTED_BOOKS_PATH, index_col=0)\n",
    "book_titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 110,256 book titles.\n",
      "time: 102 ms (started: 2022-10-26 18:36:34 +02:00)\n"
     ]
    }
   ],
   "source": [
    "title_dict = dict(zip(book_titles_df.Normalized, book_titles_df.Title))\n",
    "if FAUX_TITLES_PATH.exists():\n",
    "    faux_titles = {normalize_text(faux_title) for faux_title in FAUX_TITLES_PATH.read_text().splitlines(keepends=False)}\n",
    "else:\n",
    "    faux_titles = set()\n",
    "\n",
    "all_normalized_titles = list(set(book_titles_df.Normalized) - faux_titles)\n",
    "all_normalized_titles.sort(reverse=True, key=lambda x: len(x))\n",
    "print(f'Found {len(all_normalized_titles):,} book titles.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/slurm_tmpdir/job_21151580/ipykernel_593827/3677812895.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  posts_df = pd.read_csv(STORED_POSTS_PATH, index_col=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": "            ID  Year                                          Post Text  \\\n0        7cexh  2008                               funnyparodysffcovers   \n1        72bqq  2008  pirateshortfictionfromfantasymagazineshimmerfr...   \n2        6sr73  2008                            reviewihatedavidsedaris   \n3        6dpea  2008    sevendeadlywordsofbookreviewingnewyorktimesblog   \n4        7mbbb  2008                                    2008discoveries   \n...        ...   ...                                                ...   \n287950  v6vs1g  2022  anewwaytochooseyournextbookmostbooksaresoldonl...   \n287951  xrow2n  2022  5thannualkharkivliteratureandpoetryfestivalpur...   \n287952  xmt2pj  2022  itendtogravitatealotmoretowardstheclassicsthan...   \n287953  wqldhn  2022  needrecommendationsforagoodebookreaderappforan...   \n287954  u8sw2o  2022  vladimirnabokovauthoroflolitaadmittedtobeingpr...   \n\n       Comment Text  \n0                    \n1                    \n2                    \n3                    \n4                    \n...             ...  \n287950               \n287951               \n287952               \n287953               \n287954               \n\n[287955 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Year</th>\n      <th>Post Text</th>\n      <th>Comment Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7cexh</td>\n      <td>2008</td>\n      <td>funnyparodysffcovers</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>72bqq</td>\n      <td>2008</td>\n      <td>pirateshortfictionfromfantasymagazineshimmerfr...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6sr73</td>\n      <td>2008</td>\n      <td>reviewihatedavidsedaris</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6dpea</td>\n      <td>2008</td>\n      <td>sevendeadlywordsofbookreviewingnewyorktimesblog</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7mbbb</td>\n      <td>2008</td>\n      <td>2008discoveries</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>287950</th>\n      <td>v6vs1g</td>\n      <td>2022</td>\n      <td>anewwaytochooseyournextbookmostbooksaresoldonl...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>287951</th>\n      <td>xrow2n</td>\n      <td>2022</td>\n      <td>5thannualkharkivliteratureandpoetryfestivalpur...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>287952</th>\n      <td>xmt2pj</td>\n      <td>2022</td>\n      <td>itendtogravitatealotmoretowardstheclassicsthan...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>287953</th>\n      <td>wqldhn</td>\n      <td>2022</td>\n      <td>needrecommendationsforagoodebookreaderappforan...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>287954</th>\n      <td>u8sw2o</td>\n      <td>2022</td>\n      <td>vladimirnabokovauthoroflolitaadmittedtobeingpr...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>287955 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.25 s (started: 2022-10-26 18:36:34 +02:00)\n"
     ]
    }
   ],
   "source": [
    "posts_df = pd.read_csv(STORED_POSTS_PATH, index_col=0)\n",
    "posts_df.fillna('', inplace=True)\n",
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 395 ms (started: 2022-10-26 18:36:36 +02:00)\n"
     ]
    }
   ],
   "source": [
    "posts = list(posts_df.sample(frac=1).itertuples(index=False, name=None))    # shuffle for better time estimate for the process bar"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Book Titles to RegEx\n",
    "\n",
    "The longest book title is first, the shortest is last. The resulting RegEx always returns the longest non-overlapping matches. This way, we always match on the longest title, even if a shorter title is a substring of the long title. (e.g. Only match for 'Pride and Prejudice and Zombies' and not for 'Pride and Prejudice' in the string: 'My favourite book is \"Pride and Prejudice and Zombies\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.17 s (started: 2022-10-26 18:36:36 +02:00)\n"
     ]
    }
   ],
   "source": [
    "title_regex = '|'.join(all_normalized_titles)\n",
    "title_regex = re.compile(title_regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Posts for Book Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/287955 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f35c43231114424a860c17051b765283"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = process_map(\n",
    "    partial(get_occurrences_for_post, title_regex=title_regex),\n",
    "    posts,\n",
    "    max_workers=multiprocessing.cpu_count()//2,\n",
    "    chunksize=250\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "year, post_occ, comment_occ = zip(*results)\n",
    "\n",
    "per_year_posts = dict()\n",
    "per_year_comments = dict()\n",
    "\n",
    "for y in set(year):\n",
    "    per_year_posts[y] = dict()\n",
    "    per_year_comments[y] = dict()\n",
    "\n",
    "for y, p, c in results:\n",
    "    if p:\n",
    "        per_year_posts[y] = Counter(per_year_posts[y]) + Counter(p)\n",
    "    if c:\n",
    "        per_year_comments[y] = Counter(per_year_posts[y]) + Counter(p)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Ranked from posts:\", sorted(list(post_occ.items()), key=lambda x: x[1], reverse=True))\n",
    "# print(\"Ranked from comments:\", sorted(list(post_occ.items()), key=lambda x: x[1], reverse=True))\n",
    "# print(\"Ranked from posts and comments:\",\n",
    "#       sorted(list((Counter(comment_occ) + Counter(post_occ))\n",
    "#                   .items()), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "book_ranking = []\n",
    "for y in set(year):\n",
    "    book_ranking.extend([(y, title_dict[book_title], book_title, 'post', occurrences)\n",
    "                    for book_title, occurrences in per_year_posts[y].items()])\n",
    "    book_ranking.extend([(y, title_dict[book_title], book_title, 'comment', occurrences)\n",
    "                         for book_title, occurrences in per_year_comments[y].items()])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "book_ranking"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_frame = pd.DataFrame(book_ranking, columns=['Year', 'Title', 'Normalized Title', 'Post or Comment', 'Occurrences'])\n",
    "merged_frame.sort_values('Occurrences', inplace=True, ascending=False, ignore_index=False)\n",
    "merged_frame.reset_index(drop='index', inplace=True)\n",
    "merged_frame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_frame.to_csv(BOOK_COUNT_DF)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
