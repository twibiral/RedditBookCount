{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Book Preparation\n",
    "\n",
    "Processing the list of books to extract titles and authors. 'Normalize' them to make it easier to identify them in the reddit posts (to ignore all whitespaces and special characters)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 0 ns (started: 2022-10-19 20:20:14 +02:00)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from Functions import normalize_text\n",
    "\n",
    "NON_ALPHANUMERIC = re.compile(r'[^a-zA-Z0-9]+')\n",
    "OL_BOOK_DUMP = Path('./data/ol_dump_works_2022-09-30.txt')\n",
    "OL_RATINGS_DUMP = Path('./data/ol_dump_ratings_2022-09-30.txt')\n",
    "OL_AUTHORS_DUMP = Path('./data/ol_dump_authors_2022-09-30.txt')\n",
    "EXTRACTED_BOOKS_PATH = Path('./data/books.csv')\n",
    "MOST_FREQUENT_WORDS = Path('./data/most_common_words')\n",
    "FAUX_BOOK_TITLES = Path('./data/faux_book_titles')\n",
    "\n",
    "%load_ext autotime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-10-19 20:20:14 +02:00)\n"
     ]
    }
   ],
   "source": [
    "mult_spaces = re.compile(r'\\s\\s+')\n",
    "def clean_title(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove newlines etc. from the titles. This is NOT equal to normalize_text(...)\n",
    "    :param title: A book title.\n",
    "    :return: Cleaned book title.\n",
    "    \"\"\"\n",
    "    return mult_spaces.sub(' ', title.replace('\\n', '').replace('\\r', '')).strip()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.9 s (started: 2022-10-19 20:20:14 +02:00)\n"
     ]
    }
   ],
   "source": [
    "with open(OL_BOOK_DUMP, encoding='utf-8') as book_list:\n",
    "    complete = book_list.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 47 ms (started: 2022-10-19 20:20:36 +02:00)\n"
     ]
    }
   ],
   "source": [
    "with open(OL_RATINGS_DUMP, encoding='utf-8') as ratings_list:\n",
    "    ratings = ratings_list.readlines()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.55 s (started: 2022-10-19 20:20:36 +02:00)\n"
     ]
    }
   ],
   "source": [
    "with open(OL_AUTHORS_DUMP, encoding='utf-8') as authors_list:\n",
    "    authors = authors_list.readlines()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-10-19 20:20:41 +02:00)\n"
     ]
    }
   ],
   "source": [
    "with open(MOST_FREQUENT_WORDS, encoding='utf-8') as word_list:\n",
    "    most_common_words = {word.strip() for word in word_list.readlines()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.5 s (started: 2022-10-19 20:20:41 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# This is a list that compiles words/phrases collected during the development process that are very common and\n",
    "# can't be classified as book title with certainty when found in a post.\n",
    "if FAUX_BOOK_TITLES.exists() and FAUX_BOOK_TITLES.is_file():\n",
    "    with open(FAUX_BOOK_TITLES, encoding='utf-8') as word_list:\n",
    "        faux_titles = {word.strip() for word in word_list.readlines()}\n",
    "\n",
    "most_common_words |= faux_titles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10,749 phrases and words that are too common and are ignored as titles (e.g. \"she\", \"and\", ...)\n",
      "time: 15 ms (started: 2022-10-19 20:21:06 +02:00)\n"
     ]
    }
   ],
   "source": [
    "print(f'Found {len(most_common_words):,} phrases and words that are too common and are ignored as titles (e.g. \"she\", \"and\", ...)')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8,251,813 unique authors.\n",
      "time: 53.7 s (started: 2022-10-19 20:21:06 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# Get all authors\n",
    "all_authors = {normalize_text(x['name']) for entry in authors if 'name' in (x := json.loads(entry.split('\\t')[4]))}\n",
    "print(f'Found {len(all_authors):,} unique authors.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140,288 books with at least one rating of 2 or more in open library.\n",
      "time: 125 ms (started: 2022-10-19 20:22:00 +02:00)\n"
     ]
    }
   ],
   "source": [
    "# Remove all books that were never rated or only rated badly\n",
    "def extract_rating(entry):\n",
    "    entry = entry.split(\"\\t\")\n",
    "    return entry[0], int(entry[2])\n",
    "\n",
    "min_rating = 2\n",
    "rated_books = {rating[0] for entry in ratings if (rating := extract_rating(entry)) and rating[1] > min_rating}\n",
    "print(f'Found {len(rated_books):,} books with at least one rating of {min_rating} or more in open library.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected the titles of 110,482 books. All other 26,091,065 books were discarded.\n",
      "time: 2min 12s (started: 2022-10-19 20:22:00 +02:00)\n"
     ]
    }
   ],
   "source": [
    "title_set = set()\n",
    "\n",
    "# Remove all books that never got a rating on open library, have less than 6 or more than 100 characters in the title and not have an authors name as title.\n",
    "def process_entry(entry):\n",
    "    entry = entry.split('\\t')[4]\n",
    "    entry = json.loads(entry)\n",
    "    if 'title' in entry and 'key' in entry and entry['key'].strip() in rated_books:\n",
    "        title = clean_title(entry['title'])\n",
    "        normalized_title = normalize_text(title)\n",
    "\n",
    "        if title[:4].lower() == 'the ':     # Starts with 'The ', 'A ' or 'An '\n",
    "            normalized_title = normalized_title[3:]\n",
    "        elif title[:3].lower() == 'an ':\n",
    "            normalized_title = normalized_title[2:]\n",
    "        elif title[:2].lower() == 'a ':\n",
    "            normalized_title = normalized_title[1:]\n",
    "\n",
    "        if normalized_title and 3 < len(normalized_title) < 100 \\\n",
    "                and normalized_title not in most_common_words and normalized_title not in all_authors and normalized_title not in title_set:\n",
    "            title_set.add(normalized_title)\n",
    "            return title, normalized_title\n",
    "\n",
    "as_list = [x for entry in complete if (x := process_entry(entry))]\n",
    "print(f'Collected the titles of {len(as_list):,} books. All other {len(complete) - len(as_list):,} books were discarded.')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110,482 books indexed.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('006 and a Half', '006andahalf'),\n ('01-01-00', '010100'),\n ('05:58', '0558'),\n ('08 the Planet of the Tortoise Driver Little Prince',\n  '08theplanetofthetortoisedriverlittleprince'),\n ('10,000 ways to say I love you', '10000waystosayiloveyou')]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 94 ms (started: 2022-10-19 20:24:12 +02:00)\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(as_list):,} books indexed.')\n",
    "as_list.sort(key=lambda x: x[1])\n",
    "as_list[:5]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31 ms (started: 2022-10-19 20:24:12 +02:00)\n"
     ]
    }
   ],
   "source": [
    "f = list(filter(lambda x: len(x[1]) > 15, as_list))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 78 ms (started: 2022-10-19 20:24:12 +02:00)\n"
     ]
    }
   ],
   "source": [
    "books_df = pd.DataFrame(as_list, columns=['Title', 'Normalized'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 219 ms (started: 2022-10-19 20:24:12 +02:00)\n"
     ]
    }
   ],
   "source": [
    "books_df.to_csv(EXTRACTED_BOOKS_PATH, encoding='utf-8')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
